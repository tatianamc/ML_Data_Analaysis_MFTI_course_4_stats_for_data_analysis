{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUIZ Множественная проверка гипотез"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1 Выберите задачи, в которых обязательно нужно применять поправку на множественную проверку гипотез\n",
    "\n",
    "vСравнение эффективности лечения пациентов в подгруппах по большому количеству признаков\n",
    "\n",
    "vЛокализация различий в активности мозга испытуемых в разных экспериментальных условиях\n",
    "\n",
    "vПопарное сравнение средних большого количества выборок\n",
    "\n",
    "vВыбор инвестиционных фондов с помощью сравнения доходности каждого из них с доходностью базового актива по нескольким историческим периодам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task2 Классификатор C4.5 и три его модификации: с оптимизацией гиперпараметра m, гиперпараметра cf и с одновременной оптимизацией обоих гиперпараметров. Эти четыре классификатора сравнивались на 14 наборах данных. На каждом датасете был посчитан AUC каждого классификатора. Данные записаны в файле: AUCs\n",
    "\n",
    "Используя критерий знаковых рангов, проведите попарное сравнение каждого классификатора с каждым. Выберите два классификатора, различие между которыми наиболее статистически значимо.\n",
    "\n",
    "P.S.Для того чтобы построить пары классификаторов, воспользуйтесь функцией combinations из модуля itertools. Пример использования: combinations([a,b,c,d], 2)\n",
    "\n",
    "\n",
    "Task 3:Сколько статистически значимых на уровне 0.05 различий мы обнаружили? 4\n",
    "\n",
    "Task 4:Судя по данным из предыдущего опроса, настройка какого из параметров классификатора даёт более значимое увеличение качества?\n",
    "\n",
    "m\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aucs = pd.read_csv('AUCs.txt', sep = '\\t', header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>C4.5</th>\n",
       "      <th>C4.5+m</th>\n",
       "      <th>C4.5+cf</th>\n",
       "      <th>C4.5+m+cf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adult (sample)</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>breast cancer</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>breast cancer wisconsin</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cmc</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ionosphere</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Unnamed: 0   C4.5  C4.5+m  C4.5+cf  C4.5+m+cf\n",
       "0           adult (sample)  0.763   0.768    0.771      0.798\n",
       "1            breast cancer  0.599   0.591    0.590      0.569\n",
       "2  breast cancer wisconsin  0.954   0.971    0.968      0.967\n",
       "3                      cmc  0.628   0.661    0.654      0.657\n",
       "4               ionosphere  0.882   0.888    0.886      0.898"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "#combinations()\tp, r\tr-length tuples, in sorted order, no repeated elements\n",
    "#itertools.combinations(iterable, r)\n",
    "#Return r length subsequences of elements from the input iterable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combinations example:\n",
      "C4.5 C4.5+m : WilcoxonResult(statistic=6.5, pvalue=0.01075713311978963)\n",
      "C4.5 C4.5+cf : WilcoxonResult(statistic=43.0, pvalue=0.86126233009534803)\n",
      "C4.5 C4.5+m+cf : WilcoxonResult(statistic=11.0, pvalue=0.015906444101703374)\n",
      "C4.5+m C4.5+cf : WilcoxonResult(statistic=17.0, pvalue=0.046332729793395394)\n",
      "C4.5+m C4.5+m+cf : WilcoxonResult(statistic=22.0, pvalue=0.32782567584464062)\n",
      "C4.5+cf C4.5+m+cf : WilcoxonResult(statistic=10.0, pvalue=0.022909099354356588)\n",
      "[0.01075713311978963, 0.86126233009534803, 0.015906444101703374, 0.046332729793395394, 0.32782567584464062, 0.022909099354356588]\n"
     ]
    }
   ],
   "source": [
    "#print (list(itertools.product(*aucs)))\n",
    "print (\"combinations example:\")\n",
    "p_value=[]\n",
    "i = 1\n",
    "for i_col,j_col in itertools.combinations(['C4.5','C4.5+m','C4.5+cf','C4.5+m+cf'],2):\n",
    "    print (i_col,j_col,\":\",stats.wilcoxon(aucs[i_col] - aucs[j_col]))\n",
    "    i += 1\n",
    "    p_value.append(stats.wilcoxon(aucs[i_col] - aucs[j_col]).pvalue)\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_min = np.argmin(p_value)\n",
    "index_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#второй способ\n",
    "wilcoxon_array = np.array([])\n",
    "for i, column1 in enumerate(aucs.columns):\n",
    "    for j, column2 in enumerate(aucs.columns):\n",
    "        if j > i >= 1:\n",
    "            wilcoxon_array = np.append(wilcoxon_array,\n",
    "                                       {stats.wilcoxon(aucs[column1], aucs[column2])[1]:column1+' '+column2})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(wilcoxon_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{0.01075713311978963: 'C4.5 C4.5+m'} {0.86126233009534803: 'C4.5 C4.5+cf'}\n",
      " {0.015906444101703374: 'C4.5 C4.5+m+cf'}\n",
      " {0.046332729793395394: 'C4.5+m C4.5+cf'}\n",
      " {0.32782567584464062: 'C4.5+m C4.5+m+cf'}\n",
      " {0.022909099354356588: 'C4.5+cf C4.5+m+cf'}]\n"
     ]
    }
   ],
   "source": [
    "print(wilcoxon_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TASK 5. \n",
    "Сравнивая 4 классификатора между собой, мы проверили 6 гипотез. Давайте сделаем поправку на множественную проверку. Начнём с метода Холма. Сколько гипотез можно отвергнуть на уровне значимости 0.05 после поправки этим методом? -0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Поправка на множественную проверку"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метод Холма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "reject, p_corrected, a1, a2 = multipletests(p_value, \n",
    "                                            alpha = 0.05, \n",
    "                                            method = 'holm')\n",
    "print(reject)\n",
    "print(sum(reject))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первая поправка на множественную проверку гипотез, которой мы будем пользоваться, называется метод Холма. В рамках этой поправки мы ограничиваем вероятность того, что хотя бы на одном объекте будет ошибка, 5 %. Соответствующий метод реализован в библиотеке StatsModels, он называется multipletests, и для того чтобы передать внутрь набор наших p-value, мы их уже получили, также нужно передать уровень значимости, с которым мы работаем. Ну вот если мы хотим ограничить вероятность ошибки 5 %, тогда нам нужно передать уровень значимости 0,05. И также нужно указать метод, с помощью которого будет делаться правка. Мы используем метод Холма."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метод Бенджамини-Хохберга¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 6 Сколько гипотез можно отвергнуть на уровне значимости 0.05 после поправки методом Бенджамини-Хохберга?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте сделаем поправку на множественную проверку гипотез другим методом, например, давайте воспользуемся методом Бенджамини-Хохберга. Если в случае метода Холма мы с вами ограничивали вероятность сделать хотя бы одну ошибку, то в данном случае мы будем пытаться ограничить среднюю вероятность ошибок. Вот давайте ограничим среднюю вероятность ошибок 5 %, для этого нам снова придется использоваться коэффициент α = 0,05, и построим скорректированное значение p-value, а также снова рассчитаем, сколько же гипотез мы отвергнем с учетом данной правки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reject, p_corrected, a1, a2 = multipletests(p_value, \n",
    "                                            alpha = 0.05, \n",
    "                                            method = 'fdr_bh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print (sum(reject))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того чтобы это посчитать, нам снова придется воспользоваться той же самой функцией (функция multipletests из библиотеки StatsModels), однако в этом случае нам нужно передать ей метод ('fdr_bh'). \n",
    "\n",
    "Заменим столбцы p_corrected и rejected, которые мы с вами рассчитали предыдущим методом, на новые значения. Итак, заменяем и смотрим, как изменился DataFrame, как изменилась таблица. Структура осталась та же самая, единственное что скорректированные значения p-value и reject у нас теперь рассчитаны другим методом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Насколько корректно, на ваш взгляд, применение метода Бенджамини-Хохберга в этой задаче?\n",
    "некорректно\n",
    "8. \n",
    "Мы подозреваем, что в проведённом с C4.5 эксперименте на самом деле классификаторы сильнее отличаются друг от друга, просто нам не удалось это заметить. Что можно сделать, чтобы увеличить вероятность обнаружения различий, если они действительно существуют?\n",
    "Взять больше датасетов"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
